# plot_piv_results_groupby.py
#
# Reads PIV results (_world_data.csv) generated by PIV_GUI (v20+)
# and generates various plots (S/N, magnitude, direction, stdevs - heatmaps & histograms)
# based *only* on the original world/scaled/pixel data.
# Uses pandas groupby and tricontourf for robust handling of potentially sparse data.
# Simplified main function and includes documentation for helper functions.
# Assumes no corrected data CSV exists.
#
# Usage:
#   python plot_piv_results_groupby.py <output_base_name>
#
# Example:
#   python plot_piv_results_groupby.py ./results/my_experiment
#   (Assumes ./results/my_experiment_world_data.csv exists)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.tri as tri # For triangulation
import matplotlib
import os
import argparse
import logging

# --- Setup Logging ---
log_format = '%(asctime)s - %(levelname)s - [Plotter] - %(message)s'
logging.basicConfig(level=logging.INFO, format=log_format, datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)

# Use Agg backend for saving plots without displaying them
matplotlib.use("Agg")

# --- Plotting Helper Functions ---

def save_plot(fig, path, plot_name):
    """
    Saves a Matplotlib figure to a file with error logging.

    Args:
        fig (matplotlib.figure.Figure): The figure object to save.
        path (str): The full path (including filename) where the plot should be saved.
        plot_name (str): A descriptive name for the plot used in log messages.
    """
    try:
        fig.savefig(path, dpi=150, bbox_inches='tight')
        logger.info(f"Saved {plot_name}: {path}")
    except Exception as e:
        logger.error(f"{plot_name} saving failed: {e}", exc_info=True)
    finally:
        plt.close(fig) # Close figure after saving or error attempt

def plot_heatmap(x, y, scalar_field, title, xlabel, ylabel, cbar_label, cmap, filename, levels=15):
    """
    Generates and saves a 2D heatmap using tricontourf for potentially unstructured data.

    Handles NaNs in the scalar field.
    Inverts the Y-axis to match image coordinates (origin top-left).

    Args:
        x (np.ndarray): 1D array of X coordinates for the data points.
        y (np.ndarray): 1D array of Y coordinates for the data points.
        scalar_field (np.ndarray): 1D array of the scalar values at each (x, y) point.
        title (str): The title for the plot.
        xlabel (str): The label for the X-axis.
        ylabel (str): The label for the Y-axis.
        cbar_label (str): The label for the color bar.
        cmap (str): The name of the Matplotlib colormap to use (e.g., 'viridis', 'magma', 'hsv').
        filename (str): The full path where the plot image should be saved.
        levels (int or array-like, optional): Number of contour levels or specific level values. Defaults to 15.
    """
    logger.info(f"Generating heatmap (using tricontourf): {filename}")
    fig = None # Initialize fig to None for finally block
    try:
        # Filter out NaN coordinates and corresponding scalar values, essential for triangulation
        valid_coord_mask = np.isfinite(x) & np.isfinite(y)
        x_f = x[valid_coord_mask]
        y_f = y[valid_coord_mask]
        scalar_field_f = scalar_field[valid_coord_mask]

        # Filter out NaN scalar values AFTER filtering coordinates
        valid_scalar_mask = np.isfinite(scalar_field_f)
        x_p = x_f[valid_scalar_mask]
        y_p = y_f[valid_scalar_mask]
        z_p = scalar_field_f[valid_scalar_mask]

        if len(x_p) < 3: # Need at least 3 points for triangulation
            logger.warning(f"Not enough valid data points (< 3) for triangulation in {filename}. Skipping plot.")
            return

        # Determine plot limits and aspect ratio from filtered coordinates
        x_min, x_max = np.min(x_p), np.max(x_p)
        y_min, y_max = np.min(y_p), np.max(y_p)
        if not (x_max > x_min and y_max > y_min):
             logger.warning(f"Invalid plot limits after filtering for {filename}. Skipping plot.")
             return
        # Adjust plot size based on data aspect ratio
        plot_w = 10
        plot_h = plot_w * (y_max - y_min) / (x_max - x_min) if (x_max - x_min) > 1e-6 else plot_w
        plot_h = max(2, min(plot_h, 15)) # Clamp height
        fig, ax = plt.subplots(figsize=(plot_w, plot_h))

        # Triangulate the points
        try:
            triang = tri.Triangulation(x_p, y_p)
            # Alternative: Use Delaunay triangulation directly if needed
            # from scipy.spatial import Delaunay
            # tri = Delaunay(np.vstack((x_p, y_p)).T)
            # triang = tri.Triangulation(x_p, y_p, triangles=tri.simplices)
        except Exception as triang_err:
            logger.error(f"Triangulation failed for {filename}: {triang_err}. Skipping plot.")
            plt.close(fig)
            return

        # Determine contour levels dynamically from valid scalar data
        field_min = np.min(z_p)
        field_max = np.max(z_p)
        if field_max > field_min:
            if isinstance(levels, (int, float)): plot_levels = np.linspace(field_min, field_max, int(levels))
            else: plot_levels = levels # Use provided levels array
            extend_option = 'both'
        else: # Handle constant field case
            plot_levels = np.linspace(field_min - 0.1, field_max + 0.1, 3)
            extend_option = 'neither'

        # Create the contour plot using triangulation
        cf = ax.tricontourf(triang, z_p, levels=plot_levels, cmap=cmap, extend=extend_option)
        fig.colorbar(cf, ax=ax, label=cbar_label)

        # Set plot attributes
        ax.set_title(title)
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel)
        ax.set_aspect('equal')
        ax.invert_yaxis() # Invert Y axis
        save_plot(fig, filename, title)

    except Exception as e:
        logger.error(f"Failed to generate heatmap '{filename}': {e}", exc_info=True)
        if fig is not None: plt.close(fig) # Ensure figure is closed on error

def plot_histogram(data, title, xlabel, ylabel, filename, bins=50, range_hist=None):
    """
    Generates and saves a histogram plot for the distribution of data values.

    Args:
        data (np.ndarray): Array (can be multi-dimensional) containing the data to plot. NaNs are ignored.
        title (str): The title for the plot.
        xlabel (str): The label for the X-axis (data values).
        ylabel (str): The label for the Y-axis (usually 'Probability Density').
        filename (str): The full path where the plot image should be saved.
        bins (int, optional): Number of bins for the histogram. Defaults to 50.
        range_hist (tuple, optional): The lower and upper range of the bins. If None, range is computed from data. Defaults to None.
    """
    logger.info(f"Generating histogram: {filename}")
    fig_hist = None # Initialize for finally block
    try:
        # Flatten data and remove NaNs/Infs
        valid_data = data[np.isfinite(data)].flatten()
        if len(valid_data) == 0:
            logger.warning(f"No valid data for histogram: {title}")
            return

        # Create the histogram plot
        fig_hist, ax_hist = plt.subplots(figsize=(6, 4))
        ax_hist.hist(valid_data, bins=bins, density=True, range=range_hist)

        # Set plot attributes
        ax_hist.set_xlabel(xlabel)
        ax_hist.set_ylabel(ylabel)
        ax_hist.set_title(title)
        ax_hist.grid(True, alpha=0.5)
        if range_hist:
            ax_hist.set_xlim(range_hist) # Set x-axis limits if range is specified
        save_plot(fig_hist, filename, title)
    except Exception as e:
        logger.error(f"Failed to generate histogram '{filename}': {e}", exc_info=True)
        if fig_hist is not None: plt.close(fig_hist) # Ensure figure is closed on error

# --- Main Script Logic ---
def main(base_name):
    """Loads data from _world_data.csv using groupby and generates plots."""
    csv_path_orig = f"{base_name}_world_data.csv"

    # --- Load Data (Simplified - Assumes file exists and is valid) ---
    logger.info(f"Loading original data from: {csv_path_orig}")
    df_orig = pd.read_csv(csv_path_orig)

    # --- Calculate Statistics using GroupBy ---
    logger.info("Calculating statistics using groupby...")

    # Infer units from column names
    x_col = next((c for c in df_orig.columns if c.startswith('x_pos_')), 'x_pos_pixels')
    y_col = next((c for c in df_orig.columns if c.startswith('y_pos_')), 'y_pos_pixels')
    u_col = next((c for c in df_orig.columns if c.startswith('u_vel_')), 'u_vel_pixels/frame')
    v_col = next((c for c in df_orig.columns if c.startswith('v_vel_')), 'v_vel_pixels/frame')
    units_label = x_col.split('x_pos_')[-1]
    vel_units_label = u_col.split('u_vel_')[-1]

    # Add magnitude ('speed') column for std dev calculation
    df_orig['speed'] = np.sqrt(df_orig[u_col]**2 + df_orig[v_col]**2)

    # Group by coordinates
    # Use round() before groupby if coordinates have float inaccuracies
    coord_tolerance_factor = 1e5 # Adjust based on expected precision
    grouped = df_orig.groupby([
        (df_orig[y_col] * coord_tolerance_factor).round() / coord_tolerance_factor,
        (df_orig[x_col] * coord_tolerance_factor).round() / coord_tolerance_factor
    ])

    # Calculate means and standard deviations
    means = grouped[[u_col, v_col, 'sig2noise']].mean()
    stds = grouped[['speed', u_col, v_col]].std() # Include speed here

    # Extract coordinates from index (might need adjustment if rounding changes index type)
    coords_df = means.index.to_frame(index=False)
    xw = coords_df[x_col].values # Use original column name for key
    yw = coords_df[y_col].values # Use original column name for key

    # Extract average values
    uw_avg = means[u_col].values
    vw_avg = means[v_col].values
    sig2noise_avg = means['sig2noise'].values

    # Calculate derived averages
    magnitude_avg = np.sqrt(uw_avg**2 + vw_avg**2)
    angle_rad_avg = np.arctan2(vw_avg, uw_avg)
    angle_deg_avg = np.degrees(angle_rad_avg)

    # Extract standard deviations
    speed_stdev = stds['speed'].values
    u_stdev = stds[u_col].values
    v_stdev = stds[v_col].values
    velocity_stdev = np.sqrt(u_stdev**2 + v_stdev**2) # Velocity stdev (quadrature)

    # --- Generate Plots ---
    logger.info("Generating plots...")

    # Define labels based on loaded data
    pos_label = f"Pos ({units_label})"
    vel_label = f"Vel ({vel_units_label})"

    # Plot S/N Heatmap
    plot_heatmap(xw, yw, sig2noise_avg,
                 "Average Signal-to-Noise Ratio",
                 pos_label, pos_label, "Signal-to-Noise Ratio", 'magma',
                 f"{base_name}_sig2noise_heatmap.png")

    # Plot Magnitude Heatmap
    plot_heatmap(xw, yw, magnitude_avg,
                 "Avg Velocity Magnitude Heatmap",
                 pos_label, pos_label, f'Avg Magnitude ({vel_units_label})', 'viridis',
                 f"{base_name}_magnitude_heatmap.png")

    # Plot Magnitude Histogram
    plot_histogram(magnitude_avg, "Distribution of Average Velocity Magnitude",
                   f"Avg Velocity Magnitude ({vel_units_label})", "Probability Density",
                   f"{base_name}_magnitude_avg_histogram.png")

    # Plot Direction Heatmap (Granular Range)
    valid_angles = np.isfinite(angle_deg_avg)
    if np.any(valid_angles):
        min_angle = np.nanmin(angle_deg_avg[valid_angles]); max_angle = np.nanmax(angle_deg_avg[valid_angles])
        angle_levels = np.linspace(min_angle, max_angle, 25) if max_angle > min_angle else 15
    else:
        angle_levels = 15 # Default if no valid angles
    plot_heatmap(xw, yw, angle_deg_avg,
                 "Avg Velocity Direction Heatmap",
                 pos_label, pos_label, 'Avg Angle (degrees)', 'hsv',
                 f"{base_name}_direction_heatmap.png", levels=angle_levels)

    # Plot Direction Histogram
    plot_histogram(angle_deg_avg, "Distribution of Average Velocity Angle",
                   "Avg Velocity Angle (degrees)", "Probability Density",
                   f"{base_name}_direction_avg_histogram.png", range_hist=(-180, 180))

    # Plot Speed Stdev Heatmap
    plot_heatmap(xw, yw, speed_stdev,
                 "Speed Std Dev Heatmap",
                 pos_label, pos_label, f'Speed Std Dev ({vel_units_label})', 'plasma',
                 f"{base_name}_speed_stdev_heatmap.png")

    # Plot Speed Stdev Histogram
    plot_histogram(speed_stdev, "Distribution of Speed Standard Deviation",
                   f"Speed Std Dev ({vel_units_label})", "Probability Density",
                   f"{base_name}_speed_stdev_histogram.png")

    # Plot Velocity Stdev Heatmap
    plot_heatmap(xw, yw, velocity_stdev,
                 "Velocity Std Dev Heatmap",
                 pos_label, pos_label, f'Velocity Std Dev (Quadrature) ({vel_units_label})', 'cividis',
                 f"{base_name}_velocity_stdev_heatmap.png")

    # Plot Velocity Stdev Histogram
    plot_histogram(velocity_stdev, "Distribution of Velocity Standard Deviation",
                   f"Velocity Std Dev ({vel_units_label})", "Probability Density",
                   f"{base_name}_velocity_stdev_histogram.png")

    logger.info("Plot generation finished.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate plots from PIV GUI CSV output file (_world_data.csv).")
    parser.add_argument("base_name", help="The base name used for the PIV GUI output files (e.g., '/path/to/results/my_run').")
    args = parser.parse_args()

    main(args.base_name)
